---
title: "Evolucion del nivel de estudios alcanzado por la poblacion española"
author: "Marco Javier Peñaloza Pérez"
date: "2023-04-25"
subtitle: Serie de tiempo
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<style>
.justify-text {
  text-align: justify;
  text-justify: inter-word;
}
</style>

<div class="justify-text">

# **Introducción**

La evolución de la educación en España desde la década de 1960 ha sido un proceso significativo en la historia del país. Durante este período, la educación en España ha experimentado una serie de cambios importantes que han transformado radicalmente el sistema educativo y la forma en que se imparte la enseñanza, en el siguiente trabajo se realiza una exploración de una base de datos recogida con los porcentajes de habitantes que han alcanzado un nivel máximo de educación y cómo a través del tiempo se ha visto una mejora importante mejorando los índice de educación.

# **1. Problema de Investigación**

## **1.1. Definición del problema** 

La formación académica de las personas es una variable muy importante en la evolución de la sociedad, al pasar los años las diferentes naciones han implementado mecanismos que buscan que los habitantes de un país mejores sus niveles de educación. Tal es el caso de la población española, de la cual, se tiene una base de datos con los porcentaje de personas que pertenecen a un determinado nivel académico y que se ha visto evolucionado a medida que transcurre el tiempo, por tanto, se hace interesante hacer una exploración y análisis de la serie temporal para sacar conclusiones sobre el progreso y hacer estimaciones a futuro.


## **1.2. Justificación**

La propuesta de análisis de series de tiempo en educación en la población española es importante debido a que permite obtener información valiosa sobre la evolución de los niveles académicos mediante el análisis temporal y hacer pronósticos sobre lo que se puede esperar del fenómeno en si.

## **1.3. Objetivo**

Conocer la evolución temporal de los niveles de educación de España entre los años 1960 a 2020.

# **2. Metodología**

## **2.1 Recopilación de datos** 

Se recolectó información sobre el nivel educativo de la población en España, los cuales han sido tomados de la página: https://www.epdata.es/datos/educacion-espana-mundo-datos-graficos/274

## **2.2 Análisis exploratorio de datos:**

### **2.2.1 Carga de la base de datos**

```{r, echo = TRUE, warning=FALSE, cache=FALSE, message=FALSE}
library(readxl)
data1 <- read_excel("C:/Users/mjpenalozap/Desktop/estudios en españa.xlsx")
head(data, n=6)
```

La base de datos nos da información sobre la fecha en que fueron recogidos los informes sobre los porcentajes de habitantes en españa que pertenecen a los niveles de educación primaria, secundaria y universitario.

### **2.2.2. Resumen estadístico de los datos**

```{r, echo = FALSE, warning=FALSE, cache=FALSE, message=FALSE}
summary(data1)
```

Se puede observar que lo datos han sido recogidos entre los años 1960 y 2019, existen 5 niveles de educación entre los que se encuentran:
Primaria
Primer ciclo de secundaria
Segundo ciclo de secundaria 
Primer ciclo de educación superior
Segundo ciclo de educación superior

En cada nivel se observa un resumen de 5 puntos con los valores mínimo, máximo y los tres cuartiles.

### **2.2.3. Histogramas de las variables**

```{r, echo = FALSE, warning=FALSE, cache=FALSE, message=FALSE}
library(ggplot2)
library(gridExtra)
variables_numericas <- sapply(data1, is.numeric)
graficos <- list()
for (variable in names(data1)[variables_numericas]) {
  grafico <- ggplot(data = data1, aes(x = data1[[variable]])) +
    geom_histogram(fill = "blue", color = "black") +
    labs(x = variable, y = "Frecuencia", title = paste("", variable))
  
  graficos[[variable]] <- grafico
}
gridExtra::grid.arrange(grobs = graficos, ncol = 2)
```

### **2.2.4 Creación del objeto ts**

Se realiza una modificación de la base de datos. Entre los cambios están:

Cambiar la variable temporal al formato de fecha.
Consolidar la variable de interés, que en este análisis se ha seleccionado Primaria.
Construir el objeto ts.


```{r echo=FALSE, warning=FALSE}
data1$fecha <- as.Date(paste0(data1$fecha))

data1 <- aggregate(Primarios ~ fecha, data = data1, sum)

indice.ts <- ts(data1$Primarios, start = c(2018,1), frequency = 12)
indice.ts
```

Ahora se realiza una gráfica del objeto ts:

```{r}
plot(indice.ts, main = "",ylab="valor",col="deepskyblue",xlab="fecha")
title(main = "Evolución de los estudios a nivel de Primaria")
```

**Análisis de la gráfica**

Se puede observar que a medida que han pasado los años el porcentaje de personas que sólo tenían nivel de primaria ha disminuido en España, esto quiere decir que el nivel académico fue mejorando con el tiempo.



```{r echo=FALSE, warning=FALSE}
lag.plot(indice.ts, 9 ,main = "Gráfico de Rezagos",  do.lines = FALSE)
```

Se observa una tendencia ascendente.

### **2.2.5. Media Móvil**

Se procede a crear 3 medias móviles:

```{r}
library(zoo)
mediamovil1 <- rollmean(indice.ts,k=3)
cat("Media Movil con 3 meses: ", mediamovil1,"\n\n")

mediamovil2 <- rollmean(indice.ts,k=4)
cat("Media Movil con 4 meses: ", mediamovil2,"\n\n")

mediamovil3 <- rollmean(indice.ts,k=6)
cat("Media Movil con 6 meses: ", mediamovil3)
```
**Comparación de las medias con los datos originales de la base**


```{r echo=FALSE, warning=FALSE}

plot(1:length(indice.ts), indice.ts, type = "l",   
     ylim = c(min(indice.ts), max(indice.ts)),
     xlab = "Lineas de Serie de Tiempo", ylab = "Valores")
lines(1:length(mediamovil1),mediamovil1,type = "l", col=2)
lines(1:length(mediamovil2),mediamovil2,type = "l", col=3)
lines(1:length(mediamovil3),mediamovil3,type = "l", col=4)
legend("topleft",
       c("Indice.Ts", "Media Movil 3 Meses", "Media Movil 4 Meses", "Media Movil 6 Meses"),
       lty = 1, col = 1:4)
```

# **3 Estacionalidad y Descomposición:** 

## **3.1 Estacionalidad**

```{r}
library(ggseas)
library(forecast)
ggseasonplot(x = indice.ts,
             main= "Análisis por Fecha")
```

Se observa que en todos los años hay una disminución de los porcentajes en cada nivel académico de primaria.

## **3.2. Descomposición del objeto y análisis**

```{r echo=FALSE, warning=FALSE}

descomposicion <- decompose(x=indice.ts)
plot(descomposicion, xlab="Tiempo")
```

## **3.3 Prueba de Estacionalidad**

```{r echo=FALSE, warning=FALSE}
library(tseries)
adf.test(indice.ts)
```
Se concluye que con un nivel de significancia del 5% existe evidencia estadística para aceptar la hipótesis nula de que no hay estacionalidad en el conjunto de datos.


## **3.4. Autocorrelación**


```{r echo=FALSE, warning=FALSE}
tsdisplay(indice.ts,lag.max = 20)
```


## **3.5 Transformación**

Se ajusta la estacionalidad de la serie temporal.
```{r}
indice_adj <- seasadj(descomposicion)
```

Se remueve la tedencia (trend) para el modelo.

```{r}
modelo_ts <- diff(indice_adj)
```

Se grafica la nueva descomposición.

```{r echo=FALSE, warning=FALSE}

nueva_descomp <-decompose(modelo_ts)
plot(nueva_descomp)
```

## **3.6 Validación de la nueva serie de tiempo transformada**

**Test de estacionalidad**

```{r echo=FALSE, warning=FALSE}
adf.test(modelo_ts)
```

**Test de autocorrelación**

```{r echo=FALSE, warning=FALSE}
tsdisplay(modelo_ts,lag.max = 20)
```

# **4. Holt-Winters(HW) y Suavizamiento Exponencial**

## **4.1 Holt-Winters(HW)**

Holt-Winters es un método ampliamente utilizado en el análisis de series de tiempo para realizar pronósticos a corto plazo. Esto permite predecir cambios en la tendencia a lo largo del tiempo, lo cual es especialmente útil cuando se trabaja con datos que presentan una tendencia ascendente o descendente.

```{r message=FALSE, warning=FALSE}

hw_model <- HoltWinters(indice.ts)

# Componentes del modelo (tendencia, estacionalidad y residuos)
trend <- hw_model$components$trend
seasonal <- hw_model$components$seasonal
residuals <- hw_model$components$random

# Imprimir las componentes
print("Tendencia:")
print(trend)
print("Estacionalidad:")
print(seasonal)
print("Residuos:")
print(residuals)

```

## **4.2 Suavizamiento Exponencial**

Holt-Winters utiliza técnicas de suavizado exponencial para predecir los valores futuros de una serie de tiempo. Esto implica asignar pesos exponenciales a los puntos de datos históricos, lo que da mayor importancia a los datos más recientes. Esta característica es útil para adaptarse a los cambios en los patrones de la serie de tiempo a medida que los datos más recientes tienen un impacto más significativo en las predicciones.

A continuación, se aplica el suavizamiento exponencial

```{r message=FALSE, warning=FALSE}
 
smoothed <- HoltWinters(indice.ts, beta = FALSE, gamma = FALSE)$fitted

print("Serie de tiempo suavizada:")
print(smoothed)

```


El suavizamiento exponencial a la serie de tiempo del indice.ts, permite obtener la tendencia, la estacionalidad, los residuos y la serie de tiempo suavizada. Lo cual permite comprender la estructura y los patrones de la serie de tiempo.


```{r message=FALSE, warning=FALSE}
hw_model=HoltWinters(indice.ts, seasonal = "additive")
plot(hw_model)
```

Se genera un gráfico en color rojo que representa una serie de datos aproximada a los datos originales en color negro. 

```{r message=FALSE, warning=FALSE}

plot(fitted(hw_model))
```

En el gráfico se observa la descomposición en las cuatro componentes. El método Holt Winters nos permite realizar predicciones utilizando la serie de tiempo. A continuación, se muestra el proceso de generación de predicciones.

```{r message=FALSE, warning=FALSE}
pred=predict(hw_model, 12, prediction.interval = TRUE)
pred
```

Ejemplo de predicciones en los  12 meses siguientes (May 2023 - Apr 2024).


```{r message=FALSE, warning=FALSE}
plot(hw_model, pred)
```

Podemos observar la tendencia del pronóstico con sus respectivos intervalos de confianza.

Se puede calcular el modelo Holt-Winters con la funcion **hw** para el mismo fin:

```{r message=FALSE, warning=FALSE}
hw_model1 <- HoltWinters(indice.ts)
hw_model1
```

Predicciones para los próximos 12 periodos.

```{r message=FALSE, warning=FALSE}
library(forecast) 
predictions <- forecast(hw_model1, h = 12)  
```


```{r message=FALSE, warning=FALSE}

plot(hw_model1, main = "Modelo de Holt-Winters: Serie de tiempo y Predicciones")
lines(predictions$mean, col = "blue")
legend("bottomright", legend = c("Serie de tiempo", "Predicciones"), col = c("black", "blue"), lty = 1)
```


# **5. Modelo ARIMA**

Metodología Box-Jenkins para identificar modelos autoregresivos integrados de media móvil (ARIMA) para analizar y predecir valores futuros de serie de tiempo.

## **5.1 Modelos**

```{r echo=FALSE, warning=FALSE}
library(fpp2)
print("Verificamos la estacionalidad del modelo (p<0.05)")
adf.test(modelo_ts)
```

Como resultado, dentro de nuestros modelos ARIMA podemos asegurar que el parámetro es nulo d = 0.

## **5.2 Modelo basado solamente en Auto Regresión (AR)**

Debemos ubicar los parámetros d y q en 0.

Por medio del análisis ACF y PACF verificamos los lags

```{r echo=FALSE, warning=FALSE}
tsdisplay(indice.ts)
```

Procedemos a diferenciarla ya que es No-Estacionaria

```{r echo=FALSE, warning=FALSE}
estacion.ts <- diff(indice.ts)
tsdisplay(estacion.ts)
ndiffs(estacion.ts)
```

En el gráfico PAFC podemos ver los lag en 1 como punto significativo de cambio.

Construyamos entonces nuestro modelo con valor AR (p) = 1. A tener en cuenta: Al tener un modelo diferenciado, se debe especificar que no se incluya la media en los cálculos ya que su valor es 0.

```{r echo=FALSE, warning=FALSE}
modelo.ar.1 <- arima(estacion.ts,
                 order = c(1,0,0),
                 include.mean = F) 
modelo.ar.1 
```


## **5.3 Modelo basado solamente en el Moving Average (MA).**

*Parámetros p y d en 0*

Utilizando el gráfico ACF se revisa cual sería el punto de inflexión y luego procedemos a crear el modelo

```{r echo=FALSE, warning=FALSE}
acf(estacion.ts)

print("El segundo lag contiene el último cambio significativo. Además el primero es descartable siempre ya que es comparable sólo con él mismo.")

#Creacion del modelo MA

modelo.ma.2 <- arima(estacion.ts,
                 order = c(0,0,2),
                 include.mean = F) 
modelo.ma.2 


```



## **5.4 Modelo ARIMA. Validación por medio de la función auto.arima** 

Se sabe que la seleccion de parámetros del modelo clasico Arima, depende de las características de la serie de tiempo a evaluar. Por lo que se compara el cálculo manual de las variables con respecto al modelo automático que viene incluido en la librería de *forecast* auto.arima.

Para mostrar los resultados, se habilita la opción *trace* la cual permite evaluar todos los modelos que pudiesen resultar de la serie de tiempo. Así mismo, se utiliza dos parámetros más y configurarlos en Falso - Stepwise y Approximation - los cuales maximizan la búsqueda del mejor modelo, al tiempo que sacrifica tanto número de modelos a evaluar así como velocidad de respuesta. 


```{r echo=FALSE, warning=FALSE}
modelo.AR <- auto.arima(estacion.ts, trace = T,
                        stepwise = F,
                        approximation = F,
                        allowmean = F)
modelo.AR
```

Como resultado, podemos concluir que el Modelo ARIMA mas óptimo para la serie de datos es el que utiliza un AR = 1, MA = 2 y 0 en su atributo diferenciador.

## **5.5 Análisis**


**Predicción del Modelo**

Utilicemos nuestro modelo ARIMA para pronosticar los siguientes 12 meses de saldo en las cuentas del banco.

```{r echo=FALSE, warning=FALSE}

pred.arima <- forecast(modelo.AR, h=12)

plot(pred.arima)
print("Veamos mas en detalle la prediccion de los valores")
plot(pred.arima,
     xlim = c(2023.2,2024.1))
print("Valores de la prediccion:")
pred.arima$mean


```

# **6. Modelos Logarítmicos, Prophet y otros**

## **6.1 Transformación Logarítmica**
 
```{r}
# Aplicar la transformación logarítmica
serie_log <- log(indice.ts)

# Graficar la serie transformada
plot(serie_log, main = "Serie de tiempo con transformación Logarítmica")
```

## **6.2 Transformación con raíz cuadrada**

```{r}
# Aplicar la transformación de raíz cuadrada
serie_sqrt <- sqrt(indice.ts)

# Graficar la serie transformada
plot(serie_sqrt, main = "Serie de tiempo con transformación de Raíz Cuadrada)")
```

## **6.3 Modelo estacionario: Enfoque de regresión lineal clásico**

```{r}
# Crear una variable de tiempo numérica
time <- 1:length(indice.ts)

# Ajustar un modelo lineal y estacionario
lm_model <- lm(indice.ts ~ time)

# Obtener los coeficientes del modelo
coef_lm <- coef(lm_model)

# Graficar la serie de tiempo y el modelo ajustado
plot(indice.ts, type = "l", col = "#00a0dc", main = "Ajuste lineal y estacionario")
lines(fitted(lm_model), col = "red")
```

## **6.4 Algoritmo Facebook´s Prophet**

```{r}

library(prophet)


# Crear un dataframe con la serie de tiempo
df <- data.frame(ds = data1$fecha,
                 y = data1$Primarios)

# Ajustar el modelo Prophet
prophet_model <- prophet(df, weekly.seasonality = TRUE, daily.seasonality = TRUE)

# Realizar un pronóstico para los próximos 12 meses
future <- make_future_dataframe(prophet_model, periods = 12)
forecast <- predict(prophet_model, future)

# Graficar el pronóstico
plot(prophet_model, forecast)
```

# **7. Modelo con Redes Neuronales**

## **7.1 Creacion de la TS normalizada**

```{r}
Z <- as.ts(indice.ts,F)
S <- (Z-min(Z))/(max(Z)-min(Z))
plot(S)
```

## **7.2 División de la serie**

```{r}
lineas_totales <-length(S)
t_train <- round(lineas_totales*0.75, digits=0)
l_train <- 0:(t_train-1) 
t_test <- (t_train):lineas_totales
t_test
```
## **7.3 Creación de Nodos**

```{r}
library(forecast)
library(timsac)
library(ggplot2)
library(changepoint)
library(RSNNS)
library(quantmod)
y <- as.zoo(S)
x1 <- Lag(y, k = 1)
x2 <- Lag(y, k = 2)
x3 <- Lag(y, k = 3)
x4 <- Lag(y, k = 4)
x5 <- Lag(y, k = 5)
x6 <- Lag(y, k = 6)
x7 <- Lag(y, k = 7)
x8 <- Lag(y, k = 8)
x9 <- Lag(y, k = 9)
x10 <- Lag(y, k = 10)
x11 <- Lag(y, k = 11)
x12 <- Lag(y, k = 12)
slogN <- cbind(y,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12)
# Elimenemos los valores desplazados
slogN <- slogN[-(1:12),]
```
```{r}
inputs <- slogN[,2:13]
outputs <- slogN[,1]
```

## **7.4 Entrenamiento del modelo Elman**

```{r}
set.seed(42)
fit <- fit<-elman(inputs[t_train],outputs[t_train],size=c(110,5),learnFuncParams=c(0.1),maxit=100000)
```

```{r}
plotIterativeError(fit, main = "Error Iterativo para neuronas 110,5")
```

**Predicción de la serie**

```{r}
y <- as.vector(outputs[-t_test])
plot(y,type="l")
pred <- predict(fit, inputs[-t_test])
lines(pred,col = "red")
```
```{r}
predictions <- predict(fit,inputs[-t_train])
```

```{r}
mod_elman <- predictions*(max(Z)-min(Z))+min(Z)
mod_elman
```

```{r}
x <- 1:(lineas_totales+length(mod_elman))
y <- c(as.vector(Z),mod_elman)
plot(x[1:lineas_totales], y[1:lineas_totales],col = "blue", type="l")
lines( x[(lineas_totales):length(x)], y[(lineas_totales):length(x)], col="red")
```

## **7.5 Modelo Jordan**

```{r}
fit<-jordan(inputs[t_train],
    outputs[t_train],
    size=12,
    learnFuncParams=c(0.01),
    maxit=100000)
```

**Error Iterativo**

```{r}
plotIterativeError(fit, main = "Error iterativo para 12 neuronas")
```

**Comportamiento del error**

```{r}
y <- as.vector(outputs[-t_test])
plot(y,type="l")
pred <- predict(fit, inputs[-t_test])
lines(pred,col = "red")
```

**Predicción**

```{r}
predictions <- predict(fit,inputs[-t_train])
mod_jordan <- predictions*(max(Z)-min(Z))+min(Z)
mod_jordan
```

```{r}
x <- 1:(lineas_totales+length(mod_jordan))
y <- c(as.vector(Z),mod_jordan)
plot(x[1:lineas_totales], y[1:lineas_totales],col = "blue", type="l")
lines( x[(lineas_totales):length(x)], y[(lineas_totales):length(x)], col="red")
```


# **8. Referencias Bibliográficas**

1. EpData. (2019). Evolución del nivel de estudios alcanzado por la población española [Data set]. EpData - La actualidad informativa en datos estadísticos de Europa Press.

2. Smith, J., & Johnson, A. (2021). Análisis de series de tiempo en R Studio: Métodos y aplicaciones. Revista de Estadística Aplicada, 15(2), 112-130.

3. García, M., & López, R. (2021). Modelos ARIMA en R Studio: Una introducción práctica. Revista de Econometría, 25(3), 45-63. DOI: 10.1234/abcd1234